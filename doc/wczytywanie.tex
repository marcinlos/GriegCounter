
\section{Moduł wczytywania plików}

Zanim z plikiem dźwiękowym można zrobić cokolwiek innego, niezbędne jest odczytanie jego zawartości.
By umożliwić wygodne korzystanie z frameworku, konieczne było dostarczanie abstrakcji ukrywających
niskopoziomowe detale i różnice pomiędzy poszczególnymi sposobami reprezentacji danych (kodowanie),
oraz formatami plików (fragmentacja, kompresja itd). 

\subsection{Wewnętrzna reprezentacja danych}

W obliczu istnienia różnych sposobów cyfrowej reprezentacji dźwięku, wygodnym było zdecydować się na
wybór jednego, spójnego kodowania. Jakkolwiek wymaga to konwersji, która wprowadza pewien narzut, a
także w pewnym sensie uniemożliwia ,,użycie najlepszego formatu dla danej sytuacji'', to podejście
takie znacząco upraszcza to późniejsze przetwarzanie, pozwalając implementować je dla jednej
konkretnej reprezentacji.

Istotną kwestią jest, którego formatu użyć. Najszerzej stosowany, i oferowany przez większość
bibliotek do obsługi konkretnych formatów, jest \emph{PCM} (Pulse-Code Modulation). Stanowi on zapis
wartości amplitudy fali dźwiękowej, mierzonej dyskretnie w pewnych odstępach czasu. 

Parametrem fizycznym takiego zapisu jest częstotliwość próbkowania, określająca ile razy wartość
amplitudy jest mierzona w ciągu sekundy. Częstotliwość próbkowania zazwyczaj mieści się w zakresie
$8\,kHz - 48\,kHz$ (taki zakres obsługuje standard MP3, płyty CD standardowo zawierają dźwięk
$44.1\,kHz$).  Wynika to w pewnym stopniu z tw. o próbkowaniu (Whittaker, Nyquist, Kotelnikov,
Shannon), mówiącym w uproszczeniu, że wierne odtworzenie fali do pewnej maksymalnej częstotliwości
$M$ wymaga próbkowania z częstotliwością co najmniej $2M$. Zakres pasma słyszalnego dla człowieka
podawany jest najczęściej jako $20-20000\,Hz$, co mniej więcej odpowiada popularnym $44100\,Hz$
próbkowania. Zachowanie przebiegu sygnału przy zmianie częstotliwości próbkowania jest operacją dość
kosztowną i inwazyjną, framework operuje zatem na zapisie fali o częstotliwości próbkowania zgodnej
z wejściową.

Kolejnym aspektem PCM jest reprezentacja wartości próbek. Logicznie, wartości amplitudy są
znormalizowane do zakresu $[-1, 1]$. Co do jego kodowania, istnieje kilka popularnych rozwiązań:

\begin{itemize}
  \item 8/16/24/32-bitowe liczby całkowite ze znakiem (wartość znormalizowaną otrzymuje sie poprzez
podzielenie przez wartość bezwzględną najmniejszej reprezentowalnej liczby całkowitej) -- zapewniają
prostotę odczytu i jednorodną precyzję na całym zakresie. Zakres jest nieco niesymetryczny, ze
względu na sposób kodowania (U2)

  \item 8/16/24/32-bitowe liczby całkowite bez znaku (wartość znormalizowaną otrzymuje się poprzez
dodanie najmniejszej liczby całkowitej reprezentowalnej na danej ilości bitów w kodzie U2, i
traktowanie otrzymanej w ten sposób wartości jak w przypadku powyższym) -- sposób niemal identyczny
z powyższym, takie same wady i zalety

  \item 32/64-bitowe liczby zmiennoprzecinkowe -- symetryczny zakres, brak konieczności konwersji,
nierównomiernie rozłożona dokładność

\end{itemize}

Jako format wewnętrzny frameworku wybrane została ostatnia opcja -- 32-bitowe liczby
zmiennoprzecinkowe.  Przemawiało za tym kilka względów:

\begin{itemize}
  \item liczb zmiennoprzecinkowych można użyć bezpośrednio do obliczeń, zatem przeprowadzając
konwersję już w momencie odczytu można uniknąć przeprowadzania jej wielokrotnie w dalszej części
przetwarzania przez różne węzły

  \item najpopularniejsze formaty to liczby całkowite, 16/24-bitowe. Mantysa 32-bitowej liczyb
zmiennoprzecinkowej w standardzie IEEE-754 posiada 23 bity, zatem na przedziale $[0, 1]$ utrata
dokładności będzie niewielka bądź żadna

  \item w przypadku nietrywialnych formatów dane wejściowe przejść muszą przez kilka warstw operacji
(dekompresja, odtwarzanie oryginalnego sygnału itd), a co za tym idzie ewentualna korzyść w
przypadku, gdy format wejścia byłby zgodny z formatem wewnętrznym frameworku byłaby znikoma

\end{itemize}

Dla uproszczenia konwersji, i zmniejszenia prawdopodobieństwa popełnienia błędu (niskopoziomowa
manipulacja reprezentacją danych jest na nie podatna), stworzona została klasa pomocnicza.

\begin{java}
public class PCM {

    private static final float MAX_BYTE = Byte.MAX_VALUE;
    private static final float MAX_SHORT = Short.MAX_VALUE;
    private static final float MAX_24 = 0x7FFFFF;
    private static final float MAX_32 = Integer.MAX_VALUE;

    public static float fromU8(int b) {
        return (b + Byte.MIN_VALUE) / MAX_BYTE;
    }

    public static float fromS16(int s) {
        return s / MAX_SHORT;
    }
    
    public static float fromS24(int s) {
        return s / MAX_24;
    }
    
    public static float fromS32(int s) {
        return s / MAX_32;
    }

}
\end{java}

Wybór konkretnych funkcji podyktowany jest typami konwersji, które okazały się potrzebne podczas
implementacji parserów. Pozostałe warianty, jakkolwiek prawdopodobnie okazałyby się potrzebne przy
tworzeniu dalszych parserów, zostały pominięte.


\subsection{Realizacja wczytywania}

Spójna reprezentacja danych frameworku pozwala na wyższym poziomie abstrać od formatu pliku, jednak
istnieć musi także warstwa, która sprowadza wczytane fizycznie dane do owej reprezentacji. Różne
formaty plików audio wymagają różnego, zazwyczaj zupełnie odrębnego kodu dla zapewnienia ich
obsługi. Kod za to odpowiedzialny stanowi niejako usługę, z punktu widzenia frameworku i
korzystającego z niego programisty -- moduł (komponent) odpowiedzialny za obsługę pewnego
konkretnego rodzaju plików jest czarną skrzynką, dostarczającą pewnego podstawowego zestawu prostych
operacji, które kolejne warstwy wykorzystują do implementacji bardziej złożonej funkcjonalności.

Istnieje wiele formatów plików dźwiękowych, mniej lub bardziej popularnych. Co więcej, kolejne lata
przynoszą coraz to nowe rozwiązania. Nie sposób zapewnić \textit{a priori} wsparcia dla wszystkich
formatów. Stąd, pożądaną, choć nie kluczową cechą podsystemu wczytywania danych audio jest jego
rozszerzalność -- byłoby dobrze, gdyby framework pozwalał w możliwie prosty i nieinwazyjny (w myśl
zasady Open-Closed -- ,,otwarty na rozszerzenia, zamknięty na modyfikację'') na wzbogacenie go o
obsługę nowych formatów.

W świetle powyższych rozważań, uzasadnionym wydaje się skonstruowanie systemu wczytywania w taki
sposób, by moduły odpowiedzialne za obsługę poszczególnych formatów plików były automatycznie,
dynamicznie odnajdowane wśród dostępnych klas przez framework. Szczegółowo realizację podsystemu
odpowiedzialnego za odnajdowanie i ładowanie implementacji parserów opisuje
\hyperref[sec:odnajdywanie_implementacji]{następna sekcja}.

\begin{Note}
Od wersji 1.6 Java udostępnia taką funkcjonalność w bibliotece standardowej
(\texttt{ServiceLoader}), jednak z powodów technicznych nie było możliwe jej wykorzystanie -- patrz
\ref{sec:dlaczego_nie_service_loader}
\end{Note}

\bigskip

Poniższy diagram przedstawia poglądowo strukturę podsystemu wczytywania plików. Pewne szczegóły (np.
metody klas z innego podsystemu) są pominięte, by zwiększyć czytelność.

\IncludeUML{parsers_structure}{Struktura podsystemu wczytywania plików}

Głównym interfejsem usługi obsługiwania formatu pliku, przez który reszta frameworku komunikuje się
z poszczególnymi modułami jej dostarczającymi, jest \texttt{AudioFormatParser}. Zawiera on minimalny
zestaw metod dających dostęp do wszystkich interesujących dla frameworku aspektów pliku.

\begin{java}
public interface AudioFormatParser {

    boolean readable(InputStream stream) throws IOException;

    void extractFeatures(File file, ExtractionContext context) throws IOException, DecodeException;

    AudioStream openStream(InputStream stream) throws DecodeException, IOException;

}
\end{java}

Metoda \texttt{readable} służy do sprawdzania, czy dana implementacja usługi jest w stanie poprawnie
zinterpretować dany strumień. \texttt{extractFeatures} służy do odczytu metadanych; szczegółowy opis
systemu odczytu metadanych znajduje się \hyperref[sec:metadane]{w dalszej części dokumentu}. Metoda
\texttt{openStream} rozpoczyna odczyt właściwej zawartości pliku (danych audio). Zwraca
implementację interfejsu \texttt{AudioStream}, opisanego poniżej.

\begin{Note}
Metoda \texttt{readable} może czytać ze strumienia dowolnie dużo danych. Jeśli więc strumień po
wywołaniu ma być ponownie użyty, należy własnoręcznie zapewnić, że będzie on czytał od początku
(jeśli to pożądane, rzecz jasna).  
\end{Note}

Interfejs \texttt{AudioStream} daje bezpośredni dostęp do danych audio, zawartych w pliku. Działa
strumieniowo -- przetwarza strumień wejściowy, i na jego podstawie generuje strumień audio w
opisanym wyżej wewnętrznym formacie frameworku.

\begin{java}
public interface AudioStream extends Closeable {

    int readSamples(float[][] buffer) throws AudioException, IOException;

    SoundFormat getFormat();

}
\end{java}

Metoda \texttt{readSamples} przyjmuje dostarczony przez użytkownika bufor -- dwuwymiarową tablicę typu
\texttt{float}, gdzie pierwszy wymiar określa kanał. W wyniku wywołania fragment buforu (lub jego
całość) zostaje wypełniony danymi odczytanymi z pliku. Jeśli bufor zawiera więcej kanałów, niż ma
przetwarzany strumień, nadmiarowe tablice nie zostaną w żaden sposób wypełnione. Jeśli zaś mniej,
zostaną wypełnione, zaś dane z nadmiarowych kanałów zostaną zignorowane. Metoda \texttt{getFormat}
zwraca informacje o częstotliwości próbkowania i liczbie kanałów, opakowane w obiekt struktury
\texttt{SoundFormat}.

Punktem wejścia podsystemu wczytywania plików jest klasa \texttt{FileLoader}. Podczas tworzenia jej
instancji odnajdywane są dostępne implementacje parserów formatów plików, oraz tworzone są obiekty
udostępnianych przez nie implementacji interfejsu \texttt{AudioFormatParser}. Szczegółowy opis tego
procesu znajduje się w \hyperref[sec:odnajdywanie_implementacji]{stosownej sekcji}. Przy pomocy
metody \texttt{loadFile} załadować można podany jako argument plik audio. W rezultacie zwrócony
zostanie obiekt \texttt{AudioFile}, reprezentujacy plik wraz z pasującym do niego parserem, przy
pomocy których implementuje szereg metod, służących użytkownikowi frameworku do wykonywania operacji
na pliku. \texttt{AudioFile} potrafi również tworzyć obiekty \texttt{SampleEnumerator}, które są
niezbędne przy przetwarzaniu strumieniowym.

\begin{java}
public class AudioFile {

    private final File file;

    private final AudioFormatParser parser;

    public AudioFile(File file, AudioFormatParser parser) { ... }

    public File getFile() { ... }

    public AudioFormatParser getParser() { ... }

    public AudioStream openStream() throws IOException, DecodeException { ... }

    public SampleEnumerator openSource(int bufferSize) throws IOException, DecodeException { ... }

    public SampleEnumerator openSource() throws DecodeException, IOException { ... }

    public void extractFeatures(ExtractionContext context) throws DecodeException, 
            IOException { ...}

    public Properties extractFeatures() throws DecodeException, IOException { ... }

}
\end{java}


\subsection{Odnajdywanie implementacji parserów}
\label{sec:odnajdywanie_implementacji}

\subsubsection{Dlaczego nie \texttt{ServiceLoader}?}
\label{sec:dlaczego_nie_service_loader}

\subsection{Zaimplementowane parsery}

Framework wspiera bezpośrednio 3 formaty plików: WAV, MP3 i Vorbis.

\subsubsection{Parser WAV}

Parser formatu WAV i kontenera RIFF, w który zazwyczaj jest opakowany, z uwagi na swoją prostotę
(brak kompresji i innych przekształceń, dane bezpośrednio w formacie PCM) został napisany
własnoręcznie, przy użyciu niskopoziomowych narzędzi I/O udostępnianych przez Javę. Jedyny problem,
jaki się pojawił podczas implementacji, to konieczność odczytu typów prymitywnych zapisanych w
kolejności \textit{little-endian} -- Java oferuje jedynie obsługę \textit{big-endian}. Dla
uproszczenia kodu i uniknięcia ręcznej (choć prostej) konwersji, użyta została klasa
\texttt{LittleEndianDataInputStream} z biblioteki \emph{Guava}, która stanowi adapter na strumień
wejściowy, analogiczny do \texttt{DataInputStream} z JDK.

\IncludeUML{parser_wav}{Struktura parsera plików WAV}

Główną klasę parsera stanowi implementacja interfejsu \texttt{AudioStream} -- \texttt{WavStream},
zawierający logikę odczytu plików WAV. Używa jako klasy pomocniczej parsera plików RIFF
(\texttt{RiffParser}). RIFF to format kontenera, wewnątrz którego przechowywane mogą być różne
rodzaje plików multimedialnych. Składa się on z nagłówk głównego (\texttt{RiffHeader}), oraz pewnej
ilości fragmentów, tzw. \textit{chunków}, z których każdy posiada własny nagłówek
(\texttt{ChunkHeader}). Wewnątrz jednego z chunków znajduje się nagłówek opisujący samą zawartość
audio pliku (\texttt{WavHeader}). Po poznaniu dokładnej reprezentacji danych, \texttt{WavStream}
może odczytać zawartość pliku, wykorzystując do tego odpowiednią implementację wewnętrznego
interfejsu \texttt{PCMReader}, którego instancje odpowiadają różnym reprezentacjom PCM
(8/16/24/32-bitowe liczby całkowite)

\IncludeUML{pcm_reader}
{Klasy pomocnicze służące do odczytywania kolejnych próbek z pliku WAV}

\IncludeUML{wav_stream_create}
{Interakcje między klasami podczas tworzenia obiektu \texttt{WavStream}}


\subsubsection{Parsery MP3 i OGG}

Parser formatu MP3 został utworzony w oparciu o bibliotekę
\emph{JLayer} (\url{http://www.javazoom.net/javalayer/javalayer.html}), zaś parser Vorbis (ogg) z
użyciem biblioteki \emph{JOrbis} (\url{http://www.jcraft.com/jorbis/}). Z racji użycia bibliotek
zewnętrznych ich implementacja jest znacząco prostsza, nie jest zatem szczegółowo tu opisana.

Biblioteki użyte zostały do odczytu danych audio. Sposób pozyskania metadanych opisany jest w
\hyperref[sec:metadane_odczyt]{sekcji \ref*{sec:metadane_odczyt}}.



