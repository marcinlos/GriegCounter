
\section{Odtwarzanie}

Jedną z często wykonywanych operacji na pliku dźwiękowym jest jego odtworzenie. Na potrzeby
aplikacji (a także, by umożliwić łatwe sprawdzenie, czy parser danego formatu poprawnie dekoduje
pliki w nim zapisane), framework udostępnia taką funkcjonalność.

Biblioteka standardowa Javy -- w szczególności, \emph{Java Sound API} -- udostępniają taką
funkcjonalność poprzez stosunkowo niskopoziomowe klasy, przyjmujące surowe dane w formacie PCM.
Niestety, pakiet \texttt{javax.sound} jest niedostępny na platformie \emph{Android}. Aby zapewnić
działanie na obydwu platformach (JDK i \emph{Android}) konieczne jest albo znalezienie osobnej
biblioteki, albo stworzenie własnego podsystemu, udostępniającego jedno spójne API, realizujące je w
zależności od platformy bądź to przy użyciu \emph{Java Sound}, bądź to umożliwiających to klas
platformy \emph{Android}.

Implementacja podsystemu poszła krok dalej -- odtwarzanie dźwięku z punktu widzenia frameworku jest
dynamicznie odnajdowaną usługą, udostępnianą poprzez dobrze zdefiniowane SPI (\textit{Service
Provider Interface}). Framework sam decyduje o użytej implementacji, bazując na informacjach o
dostępnych klasach w czasie wykonania. Dzięki temu zbędne jest jawne wskazywanie implementacji --
dostępna będzie zawsze tylko jedna z nich, w zależności od platformy, na jakiej uruchamiana jest
aplikacja korzystająca z biblioteki, a framework sam ją odnajdzie. Dzięki takiemu rozwiązaniu moduł
odtwarzania jest rozszerzalny -- by zapewnić jego działanie na nowej platformie, na której nie jest
dostępne ani \emph{Java Sound API}, ani klasy Androida, wystarczy stworzyć implementację dla tej
konkretnej platformy, i zapewnić, by była dostępna w czasie wykonania.

\begin{Caution}
Jakkolwiek najprawdopodobniej nie ma po temu szczególnych przeszkód, wersja na Androida nie została
ostatecznie zaimplementowana. Dostępna jest jedynie wersja bazująca na \emph{Java Sound API},
działająca na platformach wspierających tę część JDK.
\end{Caution}

\bigskip

Poniższy diagram przedstawia ogólny zarys wewnętrznej struktury modułu odpowiedzialnego za
odtwarzanie.

\IncludeUML{playback_struct}{Struktura modułu odtwarzania}


Samo odtwarzanie dźwięku -- interakcja ze specyficznym dla platformy API umożliwiającym przekazanie
dźwięku, który ma zostać odtworzony -- to zadanie implementacji interfejsu \code{AudioOutput}.
Udostępnia on dwie wersje metody \code{write}: obydwie przyjmują bufor z danymi w formacie PCM,
które mają zostać odtworzone, przy czym wersja jednoargumentowa odtwarza całą zawartość bufora, zaś
druga jedynie fragmentu określonego przez offset początku i ilość próbek. Ponadto,
\code{AudioOutput} jest \code{Iteratee}. W poprawnej implementacji przekazanie do niego danych
poprzez metodę \code{step} powinno mieć taki sam efekt, jak wywołanie na nich \code{write}.
Framework udostępnia częściową implementację -- \code{AbstractAudioOutput}, która m. in. zapewnia
takie zachowanie.

Obiekty \code{AudioOutput} tworzone są przez instancje klasy \code{OutputFactory}, której metoda
\code{newOutput} na podstawie przekazanego formatu dźwięku (częstotliwość próbkowania, ilość
kanałów) tworzy odpowiednio skonfigurowane wyjście. Przez ten interfejs reszta frameworku komunikuje
się z dostarczycielem usługi odtwarzania. Implementacje odnajdywane i instancjonowane są poprzez
wspomniany wcześnej, dostępny od wersji 1.6 mechanizm \emph{Service Loader}. Dzieje się to w
inicjalizatorze statycznym klasy \code{Outputs}, która zapamiętuje pierwszego dostawcę usługi
odtwarzania, i udostępnia jego funkcjonalność poprzez metody \code{getFactory} i \code{newOutput}.

\begin{Note}
W przeciwieństwie do parserów, które z natury nie wykluczają się wzajemnie i koegzystują w ramach
jednej instancji aplikacji bez przeszkód, w stosunku do implementacji usługi odtwarzania dźwięku
przyjęte zostało założenie, że w danym uruchomieniu wykorzystywana będzie tylko jedna. Na chwilę
obecną nie wydaje się to specjalnie dotkliwe ograniczenie, zważywszy, że framework udostępnia
obecnie tylko jedną implementację. Założenie to umożliwia wykorzystanie mechanizmu \emph{Service
Loader} na Androidzie, jako, że opisany uprzednio problem dotyczy jedynie przypadku, gdzie w jednym
uruchomieniu odnalezione musi być wiele implementacji usługi.  
\end{Note}

Klasy te wykorzystywane są przez klasę \code{Player}, która udostępnia wysokopoziomowy, wygodny
interfejs odtwarzania, w postaci przeciążonych metod \code{play}, oraz metod umożliwiających
kontrolę trwającego odtwarzania: \code{pause}, \code{resume}, \code{stop}. Aby rozpocząć odtwarzanie
podanego pliku, \code{Player} tworzy przy użyciu klasy \code{Outputs} odpowiednią instancję
\code{AudioOutput}, a następnie podpina ją do źródła danych -- uzyskanego przez wywołanie
\code{openSource} obiektu \code{SampleEnumerator}. Wspomniane wcześniej metody kontrolujące
odtwarzanie zaimplementowane są one jako wywołania odpowiadających im metod z klasy
\code{SampleEnumerator}. Odtwarzanie domyślnie przebiega w osobnym wątku, prywatnym dla obiektu
\code{Player}. Aby zakończyć pracę maszyny wirtualnej, należy zakończyć uprzednio wątki używane
przez \code{Player}a. Służą do tego metody \code{shutdown}. Działają tak, jak analogicznie nazwane
metody interfejsu \code{ExecutorService} z JDK.

Obiekt klasy \code{Player} może odtwarzać kolejno wiele utworów, jeden po drugim, aczkolwiek tylko
jeden w danym momencie. Ten tymczasowy stan -- używane obecnie źródło danych
(\code{SampleEnumerator}) oraz ujście dźwięku (\code{AudioOutput}) przechowywane są w strukturze
\code{TrackPlayback}. \code{Player} deleguje do niej wszelkie operacje związane bezpośrednio z
trwającym w danym momencie odtwarzaniem.

Możliwe jest również, zamiast otwierania pliku i czytania jego zawartości w osobnym wątku, podpięcie
odtwarzacza pod istniejący obiekt klasy \code{SampleEnumerator}. W ten sposób osiągnąć można
synchronizację pomiędzy odtwarzaniem, a resztą przetwarzania. Uczynić to można za pomocą metody
\code{prepare}. W przeciwieństwie do przeciążonych wersji metod \code{play}, nie rozpoczyna ona
odczytu danych ze źródła we własnym prywatnym wątku, a jedynie podpina odpowiednie ujścia
(\code{Iteratee}). Aby rozpocząć odtwarzanie, trzeba ręcznie uruchomić przekazane jako parametr
źródło. Pozwala to użyć obiektu \code{Player} jako zwykłej jednostki przetwarzania, co niekoniecznie
jest możliwe w przypadku \code{play}, z uwagi na przejęcie przez system odtwarzania pełnej kontroli
nad źródłem.

Użytkownik frameworku ma możliwość otrzymywania notyfikacji o zdarzeniach dotyczących procesu
odtwarzania realizowanego przez konkretny obiekt klasy \code{Player}, oraz jego postępu w czasie
poprzez interfejs \code{PlaybackListener}. Kolekcja jego implementacji przechowywana jest w obiekcie
\code{Player}, który wywołuje na nich odpowiednie metody w reakcji na zdarzenia.


\subsubsection{Implementacja z użyciem \emph{Java Sound API}}

Framework udostępnia na chwilę obecną jedną implementację usługi odtwarzania dźwięku, zbudowaną przy
użyciu klas z pakietu \code{javax.sound.*}. Jest ona stosunkowo prosta, dzięki minimalistycznemu
interfejsowi usługi. Na podstawie przekazanych parametrów dźwięku tworzony jest obiekt
implementujący interfejs \code{SourceDataLine}, który następnie należy przygotować do przyjmowania
dźwięku poprzez wywołanie metody \code{open}, a potem można już przesyłać do niego dane dźwiękowe.
\emph{Java Sound API} nie obsługuje danych PCM zapisanych przy pomocy liczb zmiennoprzecinkowych,
konieczna zatem jest konwersja do jakiegoś wspieranego formatu. Wybór padł na 16-bitowe liczby
całkowite ze znakiem, z kolejnością \textit{big-endian}.

\begin{NoteLong}
Istotne znaczenie ma wybór wielkości bufora -- zbyt małe wielkości źle wpływają na wydajność
odtwarznia, oraz prowadzić mogą do krótkich ,,dziur'', zbyt duże natomiast drastycznie zmniejszają
responsywność systemu. W przypadiu wyświetlania wyników przetwarzania w czasie rzeczywistym
odtwarzanie jest wąskim gardłem, ograniczającym szybkość całego procesu, zatem czekanie na
opróżnienie bufora danych audio przy posyłaniu ich do odtwarzania jest jedynym widocznym momentem
,,przerwy'', w którym nastąpić może odrysowanie interfejsu. Jeśli więc bufor jest duży, jego
zapełnienie, a więc i odrysowanie interfejsu, następuje rzadziej. Wielkość bufora jest
konfigurowalna, domyślnie używana jest empirycznie dobrana, dająca subiektywnie ,,dobre'' efekty.
\end{NoteLong}

